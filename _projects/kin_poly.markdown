---
layout: page
title: ContextEgoPose
description: Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation
img: /assets/img/projects/kin_poly/teaser.gif
importance: 1
type: research
---


<h3 style="text-align: center;font-size:30px"> Dynamics-Regulated Kinematic Policy <br> for Egocentric Pose Estimation </h3>
<h4 style="text-align: center;color:DodgerBlue"> Zhengyi Luo, Ryo Hachiuma, Ye Yuan, Kris M. Kitani  </h4>
<h5 style="text-align: center;"> arXiv 2020 </h5>


<div class="row">
    <div class="col-sm-12 mt-3 mt-md-0 mx-md-0 ml-md-0">
        <img class="img-fluid rounded z-depth-0" src="{{ '/assets/img/projects/kin_poly/teaser.png' | relative_url }}" alt="" title="Kin-Poly image"/>
    </div>
</div>
<!-- <div class="caption">
    This image can also have a caption. It's like magic.
</div> -->
<br>
<p  align="justify">
    We propose a method for object-aware 3D egocentric pose estimation that tightly integrates kinematics modeling, dynamics modeling, and scene object information. Unlike prior kinematics or dynamics-based approaches where the two components are used disjointly, we synergize the two approaches via dynamics-regulated training. At each timestep, a kinematic model is used to provide a target pose using video evidence and simulation state. Then, a prelearned dynamics model attempts to mimic the kinematic pose in a physics simulator. By comparing the pose instructed by the kinematic model against the pose generated by the dynamics model, we can use their misalignment to further improve the kinematic model. By factoring in the 6DoF pose of objects (e.g., chairs, boxes) in the scene, we demonstrate for the first time, the ability to estimate physically-plausible 3D human-object interactions using a single wearable camera. We evaluate our egocentric pose estimation method in both controlled laboratory settings and real-world scenarios.
</p>
<br>


<div class="row">
    <div class="col-sm-12 mt-3 mt-md-0 mx-md-0 ml-md-0">
        <img class="img-fluid rounded z-depth-0" src="{{ '/assets/img/projects/kin_poly/overview.png' | relative_url }}" alt="" title="Kin-Poly image"/>
    </div>
</div> 
Our framework first learns a Universal Humanoid Controller (UHC) from a large MoCap dataset. The learned UHC can be viewed as providing the lower level muscle skills of a real human, trained from mimicking thousands of human motion sequences. Using the trained UHC, we learn our kinematic policy through dynamics-regulated training. The kinematic policy provides per-step target motion to the UHC, forming a closed-loop system that operates inside the physics simulation to control a humanoid. For more details, please checkout our paper and supplementary video: 



<h3 style="color:darkblue">Supplementary Video</h3>

<div class="embed-container">
<center>
  <iframe
      src="https://www.youtube.com/embed/QAK9jTUHRQU"
      width="700"
      height="480"
      frameborder="0"
      allowfullscreen="">
  </iframe>
  </center>
</div>

<br>
<br>
<br>
<h3 style="color:darkblue">Paper and Code</h3>

<div>
{% for paper in site.data.publications.publications %}
    {% if paper.title ==  "Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation" %}
        {% include single_paper.html %}
    {% endif %}
{% endfor %}
</div>

<br>
<br>
<br>
<p> -- </p>